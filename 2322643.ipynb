{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22211406-52cf-41d3-b172-06a4fada1e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag, ne_chunk\n",
    "#!pip install inflect\n",
    "import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b9a695-f505-4c7a-a62c-93c61079732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = inflect.engine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6354abde-d436-41c1-ab33-e3be8bee1371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "search: who  published the book by Paull?\n"
     ]
    }
   ],
   "source": [
    "query=input(\"search:\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99d7a014-0760-4a1e-8414-dda68bd81616",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_synonyms = {\n",
    "    \"book\": [\"books\",\"book\", \"novel\", \"tome\", \"manual\", \"guide\", \"text\",  \"work\", \"volume\", \"manuscript\",  \"paper\", \"story\", \"read\", \"novella\", \"journal\", \"e-book\", \"paperback\", \"hardcover\", \"anthology\"],\n",
    "    \"author\": [\"author\", \"writer\", \"novelist\", \"scribe\", \"literary figure\", \"poet\", \"playwright\", \"penman\"],\n",
    "    'hasauthor': [\"hasauthor\", \"writtenby\", \"wrote\"],  \n",
    "    \"Publisher\": [\"publisher\", \"publishing house\", \"press\", \"editor\", \"printer\", \"distributor\"],\n",
    "    \"Has_category\": [\"category\", \"type\", \"genre\"],\n",
    "    \"name\": [\"name\", \"title\", \"names\",\"who\"],\n",
    "    \"Edition\": [\"edition\", \"version\", \"release\", \"issue\", \"printing\"],\n",
    "    \"publication_date\": [\"date of publishing\", \"release date\", \"publication date\", \"publication\"],\n",
    "    \"requests\": ['Requests', 'request', 'loan_request', 'user_request'],\n",
    "    \"Loan\": ['Loan', 'loan', 'loan_event', 'borrowed_book', 'borrowed', 'loaned', 'lends'],\n",
    "    \"Shelf_location\": ['Shelf_location', 'shelf_location', 'book_location', 'shelf_position', 'location'],\n",
    "    \"Awards\": ['award', 'recognition', 'prize', 'honor', 'reward'],\n",
    "    \"user\": [\"reader\", \"user\"],\n",
    "    \"Ebook\": ['digital book', 'digital copy'],\n",
    "    \"GivesAward\": ['gives_award', 'awarded_by',],\n",
    "    \"receivesaward\": ['receives_award', 'awarded_to','awarded'],\n",
    "    \"requestsbook\": ['requests_book', 'book_request','requested'],\n",
    "    \"PublishedBy\": [\"published\", \"publishedby\"],\n",
    "     \"copiesleft\":[\"availability\",'no of copies'],\n",
    "      \"borrows\":[\"due\",\"borrow\"]\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29b20331-8723-4df8-9a06-7c6188bc1d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['requests', 'Awards', 'Loan', \"book\", \"author\", \"Publisher\", \"Ebook\", \"Category\", \"Shelf_location\", \"user\"]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e92f949c-a6e9-4445-adf2-7efab2e8563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_list = ['Has_category', \"copiesleft\",'publication_date', 'categoryIsOf', 'IsAuthorOf', 'hasAuthor', \n",
    "'PublishedBy', 'Published', 'Has_shelfloc', 'Islocationof', 'Has_sequel', 'IsSequelTo', 'Has_prequel', 'IsPrequelTo', \n",
    "             'GivesAward', 'receivesaward', 'Has_format', 'borrows', 'requestsbook', 'LoansBook', 'name',\n",
    "             'Age', 'shelfno', 'returnDate', 'Ratings', 'Gender']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e4271a-6463-432d-b814-8ac63a490921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8b7c4ca-2e2a-439e-92c7-41079dd4a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization():\n",
    "    processed_query = re.sub(rf\"[{re.escape(punctuation)}]\", \"\", query)  # Remove punctuation\n",
    "    processed_query = \" \".join(processed_query.split())  # Remove extra spaces\n",
    "    return processed_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5600f336-cf92-412f-ae04-00482ce9dc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Welcome\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4df2139b-a5a3-4e8f-aae4-7afb7125658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenization():\n",
    "    q = normalization()\n",
    "    t = word_tokenize(q)\n",
    "    tokens = [token for token in t if token.strip()]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1ac910a-c827-42b0-bff7-b36705244973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Welcome\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "def lemma():\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = tokenization()  \n",
    "    lemmatized_words = [lemmatizer.lemmatize(token, 'n') for token in tokens]\n",
    "    sentence_with_lemmatized_words = \" \".join(lemmatized_words) \n",
    "    return sentence_with_lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e18b8db-cb88-4997-b3a9-857344c58d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who published the book by Paull\n",
      "['who', 'published', 'the', 'book', 'by', 'Paull']\n"
     ]
    }
   ],
   "source": [
    "q1=normalization()\n",
    "q2=tokenization()\n",
    "q3=lemma()\n",
    "print(q1)\n",
    "print(q2)\n",
    "#print(q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "29a0208f-6957-49ca-bdcc-5ef37659b66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Welcome\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "42711c10-7dea-4652-8df7-f59f18965456",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8f213dd5-5b5b-444f-8112-274102fcb4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.remove(\"who\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b3aebe53-2239-4c2e-b533-d688a5f67f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.add(\"list\")\n",
    "stop_words.add(\"List\")\n",
    "stop_words.add(\"Retrieve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "05b25daa-ec9a-4c89-813f-27ad9ae76b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def removal():\n",
    "    tokens = word_tokenize(q3)\n",
    "    filtered_words = [x for x in tokens if x not in stop_words]\n",
    "    sentence_without_stop_words = \" \".join(filtered_words)\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "375ee3e2-aaf5-444c-b9f1-7c1d5d484955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['who', 'published', 'book', 'Paull']\n"
     ]
    }
   ],
   "source": [
    "q4=removal()\n",
    "print(q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cfe80237-25d5-45e7-a92e-8ab57717cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_synonyms():\n",
    "     \n",
    "    \n",
    "    replaced_tokens = []\n",
    "    for word in q4:\n",
    "        for key, synonyms in book_synonyms.items():\n",
    "            if word.lower() in synonyms:\n",
    "                replaced_tokens.append(key) \n",
    "                break \n",
    "        else:\n",
    "            replaced_tokens.append(word)  \n",
    "    \n",
    "    return replaced_tokens\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "08981bcf-f748-4640-85a9-a0cb4e29b71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'PublishedBy', 'book', 'Paull']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "q5=replace_with_synonyms()\n",
    "print(q5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "66d17926-6c78-4192-8c5c-8d2a3651c4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Welcome\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "65e3010f-3a8b-4242-9a23-91a03ae202dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('name', 'NN'), ('PublishedBy', 'NNP'), ('book', 'NN'), ('Paull', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "def create_pos_tags(sent):\n",
    "   \n",
    "    sent = ' '.join(sent)  \n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    " \n",
    "tags = create_pos_tags(q5)\n",
    "print(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9640a940-edb4-459e-83dd-b2d52fde455c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Welcome\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Welcome\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "#S!pip install inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "83dcee80-29c7-499d-a9b1-953db63446c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities: (S name/NN (ORGANIZATION PublishedBy/NNP) book/NN (PERSON Paull/NNP))\n",
      "Word: name, POS: NN\n",
      "Word: book, POS: NN\n",
      "Singular Class: False\n",
      "Individuals: ['PublishedBy', 'Paull']\n",
      "Classes: ['Book']\n",
      "Properties: ['Name']\n"
     ]
    }
   ],
   "source": [
    "named_entities = ne_chunk(tags)\n",
    "individuals = []\n",
    "classes = []\n",
    "properties = []\n",
    "print(\"Named Entities:\", named_entities)\n",
    "for entity in named_entities:\n",
    "    if hasattr(entity, \"label\"): \n",
    "        individual = ' '.join(c[0] for c in entity)\n",
    "        if individual.lower() in class_list: \n",
    "            classes.append(individual)\n",
    "            properties.append(word)\n",
    "        else:\n",
    "            individuals.append(individual)\n",
    "    else:\n",
    "        word, tag = entity\n",
    "        print(f\"Word: {word}, POS: {tag}\")\n",
    "        if word in prop_list:  \n",
    "            properties.append(word.title())\n",
    "       \n",
    "        if tag == \"NNP\" or tag == \"NNS\" or word.lower() in class_list:  \n",
    "            singular_class = p.singular_noun(word)  # Convert to singular\n",
    "            print(\"Singular Class:\", singular_class)\n",
    "            if singular_class:\n",
    "                classes.append(singular_class.capitalize())\n",
    "            else:\n",
    "                classes.append(word.capitalize())\n",
    "        elif tag == \"VBP\":  \n",
    "            properties.append(word.title())\n",
    "print(\"Individuals:\", individuals)\n",
    "print(\"Classes:\", classes)\n",
    "print(\"Properties:\", properties)\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6271d57d-3f58-4509-b89c-895d3109b5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SPARQLWrapper in c:\\users\\welcome\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: rdflib>=6.1.1 in c:\\users\\welcome\\anaconda3\\lib\\site-packages (from SPARQLWrapper) (7.1.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\welcome\\anaconda3\\lib\\site-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install SPARQLWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "790ec453-9d59-4ce6-b76f-26216bf1719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "sparql = SPARQLWrapper(\"http://localhost:3030/Library/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "PREFIX Libs:<http://www.semanticweb.org/welcome/ontologies/2024/9/untitled-ontology-8#>\n",
    "SELECT ?aname \n",
    "WHERE {\n",
    "  ?author  a Libs:Author ;\n",
    "       Libs:RecievesAward ?award  ;\n",
    "  \t  Libs:Name ?aname .\n",
    "}\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)  # Ensure JSON format\n",
    "results = sparql.query().convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd17c143-5485-4c93-b247-b55cb86a58cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9326a964-b80f-426e-98b1-22c144c2a844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author:  Monroe\n",
      "author: Paull\n",
      "author:  Ethridge\n",
      "author:  Lister\n",
      "author: Outstanding Poetry Collection\n",
      "author:  Rich\n",
      "author:  Anonymous (EDT)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for res in results[\"results\"][\"bindings\"]:\n",
    "    author = res['aname']['value']\n",
    "    print(f\"author:\",author)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2a854-f978-469e-ae15-75e8bf8712bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7dc89f-8fad-4bb8-9f26-f8569213aece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03f1131-1b73-40ed-822a-1e62f4751201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8419306a-e847-4c86-b11b-745146f63a38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
